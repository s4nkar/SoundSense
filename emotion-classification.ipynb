{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af743a7",
   "metadata": {},
   "source": [
    "# **Library and Module Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fed4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports & Setup\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aafca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load file paths and extract labels\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    emotion = parts[2]  # DIS, HAP, etc.\n",
    "    emotion_map = {\n",
    "        'ANG': 'angry',\n",
    "        'DIS': 'disgust',\n",
    "        'FEA': 'fear',\n",
    "        'HAP': 'happy',\n",
    "        'NEU': 'neutral',\n",
    "        'SAD': 'sad'\n",
    "    }\n",
    "    return emotion_map.get(emotion, 'unknown')\n",
    "\n",
    "# Assuming crema_path points to folder with audio\n",
    "crema_path = \"dataset\"\n",
    "data = []\n",
    "\n",
    "for file in os.listdir(crema_path):\n",
    "    if file.endswith(\".wav\"):\n",
    "        emotion = parse_filename(file)\n",
    "        path = os.path.join(crema_path, file)\n",
    "        data.append((path, emotion))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"file\", \"emotion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Extraction\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr).T, axis=0)\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y).T, axis=0)\n",
    "    rms = np.mean(librosa.feature.rms(y=y).T, axis=0)\n",
    "\n",
    "    return np.hstack([mfcc, chroma, contrast, zcr, rms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe87a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7442/7442 [01:20<00:00, 92.02it/s] \n"
     ]
    }
   ],
   "source": [
    "# Extract features for each audio file\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        features = extract_features(row[\"file\"])\n",
    "        X.append(features)\n",
    "        y.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {row['file']} - {str(e)}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd278b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.70      0.65       255\n",
      "     disgust       0.37      0.38      0.38       254\n",
      "        fear       0.33      0.26      0.29       254\n",
      "       happy       0.43      0.35      0.38       254\n",
      "     neutral       0.40      0.37      0.38       218\n",
      "         sad       0.48      0.62      0.54       254\n",
      "\n",
      "    accuracy                           0.45      1489\n",
      "   macro avg       0.44      0.45      0.44      1489\n",
      "weighted avg       0.44      0.45      0.44      1489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Train a basic SVC classifier\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

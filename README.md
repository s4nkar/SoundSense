# 🎧 SoundSense  
### Vocal Anomaly Detection: Identifying Emotional Inconsistencies in Speech

SoundSense is a research project focused on detecting emotional mismatches between what is said (text) and how it's said (audio). By combining NLP and voice analysis, we aim to identify **vocal anomalies** — such as when someone says "I'm fine" but sounds sad.

---

## 🗂️ Datasets Used

1. **CREMA-D** – Crowd-sourced Emotional Multimodal Actors Dataset  
   🔗 [View on Kaggle](https://www.kaggle.com/datasets/ejlok1/cremad)

2. **Emotion Dataset (Text-Based)** – Twitter text samples labeled with emotional categories  
   🔗 [View on Kaggle](https://www.kaggle.com/datasets/bhavikjikadara/emotions-dataset)

---

## 📌 Project Objectives

- 🎙️ **Voice Emotion Classification** using audio features like tone, pitch, and pace
- 🧠 **Text-Based Emotion Detection** using pre-trained BERT models
- ⚖️ **Cross-Modal Comparison** to flag inconsistencies between vocal tone and spoken content

---

## 📬 Contact

📩 DM or email me for access to:
- The cleaned datasets  
- Trained models  

---

## 📦 Getting Started

Clone the project:

```bash
git clone https://github.com/s4nkar/SoundSense.git
cd SoundSense
# run main.ipynb if you already have trained models